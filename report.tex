% Predicting Diseases with Data Science
% Jacob Sánchez Pérez (jacob@san.contact)
% Data Science (CO3722)
% University of Central Lancashire

\documentclass[a4paper,12pt]{article}

% Links
\usepackage{hyperref}

% PDF Metadata
\hypersetup{
    hidelinks,
    pdftitle={Predicting Diseases with Data Science},
    pdfauthor={Jacob Sánchez}
}

% Code
\usepackage{minted}

% Referencing and more
\usepackage[british]{babel}
\usepackage{csquotes}
\usepackage[style=apa,backend=biber]{biblatex}

% Images
\usepackage{graphicx}
\graphicspath{ {./images/} }

% Graphs
\usepackage{pgfplots}
\pgfplotsset{width=10cm,compat=1.9}
\usepgfplotslibrary{external}
\tikzexternalize

\title{Predicting Diseases with Data Science}
\author{Jacob Sánchez Pérez\\ University of Central Lancashire\\\texttt{jsanchez-perez@uclan.ac.uk}}
\date{}

\addbibresource{references.bib}

\begin{document}

\maketitle


\section{Introduction}

% PROMPT
% This section will introduce your project, your business, specific Use Case and potential source of a dataset for analysis.

% NOTES
% The business I have chosen is healthcare

Data science applies different methods, both qualitative and quantitative, in order to solve relevant problems and make predictions \parencite[78]{Waller2013}.
One industry that can benefit from the applications of data science is the healthcare industry.
According to the \textcite{oecd2010health}, improving productivity in the healthcare sector translates to public spending savings.
McKinsey estimated that data analytics can reduce healthcare expenses by \$300 B to \$450 B per year in the U.S. alone \parencite{Groves2013}.
One way of improving healthcare is to utilise data science to process the massive amounts of electronic health records that exist \parencite{Dalianis2015}.
Data collected in healthcare can come in the form of physician notes, medical records, patient scans, and patient sensor data (such as wearables) \parencite{Adam2017}.
However, obtaining said data may present several challenges due to patient privacy. 

Areas in healthcare that could have the most impact from the application of data science include early detection of diseases, precision medicine, optimisation of workflows, value-based healthcare, infection prevention and control, and clinical research \parencite[9]{Consoli2019}.
This report is centred around the application of data science to predict diseases.
It will review in detail the process of data analysis, from locating a data source, processing the data, and finally visualising and interpreting the results.

\section{Data Science for Healthcare}

% PROMPT
% This section will relate specifically to your business and Use Case and their approach or potential application for the use of data science.
% This will cover the challenge of acquiring or using specific data sources for your Use Case, approaches to data processing, description of proposed machine learning  algorithms and their design, opportunities for data visualisation and the methods for analysing/interpreting the data required to gain business competitive advantage.

\subsection{Challenges}

There exist several limitations to the data freely available for analysis.
As \textcite[2]{Dalianis2015} points out, this is mainly due to the existence of sensitive data about patients in medical records.
A cross-sectional survey found that the two biggest perceived obstacles towards obtaining healthcare data were conflicts of laws and data standardization \parencite{Kim2019}.

\subsubsection{Privacy Concerns}

Regulatory requirements, for instance, the General Data Privacy Regulation (GDPR) in the European Union and the Health Insurance Portability and Accountability Act (HIPAA) in the U.S., protect data that can be used to identify a patient \parencite{Iyengar2018}.
GDPR requires explicit consent of the subject to process personal data. Obtaining said consent results impractical in big data analytics, where it is necessary to process several terabytes worth of data \parencite{Hintze2018}.

However, there are other criteria which can allow data to be processed for purposes such as research and analysis.
This criteria calls for \textquote{appropiate safeguards} to be in place, which includes encryption and pseudonymisation \parencite[151]{Hintze2018}.
Pseudonymisation is a way to de-identify information, and consists of replacing or removing direct identifiers, such as names, phone numbers, and other data points that could be directly attributed to a particular subject \parencite[146-147]{Hintze2018}.
Due to the large amounts of data present in health records, de-identification should ideally be automated.
\textcite{Dernoncourt2016} described an automated de-identification technique using neural networks, that achieved 97\%+ precision on different datasets.
However, no method is perfect and this is still a limiting factor in healthcare data availability.
Furthermore, some debate exists about the need for strict de-identification, and how it can affect the availability of data.
\textcite[2]{Shin2018} argues that de-identification can lead to a distortion and loss of detailed data, which can greatly impact the results of a study.
Likewise, \textcite{Kim2019} revealed that almost half (45.8\%) of all participants in a survey thought that a revision in legislation was necessary to reduce obstacles when using healthcare data.
However, it is important to remember that big data analytics can still have consequences for individuals.
Some de-identification methods are vulnerable to correlation attacks, which can identify individuals through indirect identifiers \parencite{Abouelmehdi2018}.
As \textcite{Abouelmehdi2018} points out, analytics should verify privacy agreements are respected, and sensitive information should remain private.

\subsubsection{Processing Concerns}

In addition to the legal issues, there is another major obstacle when using healthcare data.
This comes in the form of data processing problems, specially with clinical notes, since these can contain misspelled words, medical jargon, and non-standard words \parencite{Dalianis2015}.
In addition, data is oftentimes collected from systems with different and incompatible formats \parencite[34]{Consoli2019}.
Therefore some amount of preprocessing will need to take place before analysing the data.

\subsection{Data Sourcing}

\subsubsection{Healthcare Data Sources}

Despite the many difficulties that exist in making healthcare data ready for research purposes,
some de-identified datasets have been made available online.
\textcite{Dalianis2015} mentions a few, listed below.

\paragraph{MIMIC-II} A collection of data from ICU patients,
spanning 7 years and ~27,000 patient admissions.
The dataset contains patient demographics, intravenous medication drip rates,
laboratory test results, physiological waveforms and vital signs recorded at bedside.
The dataset can be accessed after registration free of charge \parencite{Lee2011}.

\paragraph{MIMIC-III} A successor to the \textit{MIMIC-II} dataset,
it contains more than a decade and 50k+ patient admissions worth of data.
It contains a wide range of data including demographics, notes and reports,
tests, along with bedside monitoring data.
As its predecessor, it has an open access policy \parencite{Johnson2016}.

\paragraph{THIN} It is an ongoing data collection system which starts at 1994,
and represents 6\% of the UK population.
It contains records from general practices.
The dataset can only be accessed by those with special authorisation,
such as research organisations \parencite{Lewis2007}.

\paragraph{n2c2} Formerly known as \textit{i2b2} , it is a collection of datasets
of topics including smoking, obesity, medication, heart disease and psychiatry,
each with thousands of records.
The dataset requires registration and access request approval, yet is free of cost.

\medskip
Additionally, there are many other websites dedicated to the publication of open
access healthcare datasets, for instance:

\paragraph{HealthData.gov} The United States government operates the website HealthData.gov\footnote{\url{https://healthdata.gov}} through the
\textit{Open Government Initiative} \parencite{Marc2015}, for general purpose
healthcare-related datasets.

\subsubsection{Dataset Choice}

For the purpose of this report, the \textit{n2c2} dataset was chosen, 


\subsection{Data Processing Techniques}

De-identification techniques will not be covered here,
since all of the data that can be obtained will have been de-identified beforehand.
After de-identification, one of the biggest challenges with healthcare data is making sense of it.

\subsubsection{Data Cleaning}

Before attempting to perform any data analytics, it is a good idea to verify the integrity and quality of the dataset. Factors that can affect the quality of a dataset include: missing values, misspellings, duplicates, and mixed formats \parencite{Chu2016}. These can present themselves as outliers, values that are more than two standard deviations away from the mean \parencite{Hellerstein2008}. \textcite{Hellerstein2008} mentions robust estimators, resampling, and exploratory data analysis as ways to detect outliers in order to improve the data quality. While this may account for quantitative data, such as integers and floating point numbers, categorical variables must also be taken care of. Categorical data are words or names that \textquote[{\cite{Hellerstein2008}}]{assign data into categories or groups}, such as \textquote{dog} and \textquote{canine}.
While this is usually handled by deduplication, \textcite{Cerda2018} described an approach that encodes the similarity between categories, showing gains in performance.

\subsubsection{Text and Strings Specifics}

One of the most common ways to represent text for machine learning purposes is called \textit{bag-of-words}.
It consists of keeping a record of every unique word in the text, along with the number of times it is used.
Everything else, such as structure, formatting, and punctuation is discarded \parencite[327]{Mueller2017}.
There are additional measures that can improve the quality of data such as \textit{stopwords} (discarding frequent words) \parencite[327-336]{Mueller2017}, and \textit{term frequency–inverse document frequency} (rescale features by their expected importance);
as well as ways to improve the \textit{bag-of-words} technique, such as n-grams, stemming and lemmatization \parencite[339,344]{Mueller2017}.

In healthcare, some techniques that might improve the quality of free-text data may include detection of negation and spelling mistakes, abbreviation normalisation, and named entity recognition \parencite{Dalianis2015}.

\subsection{Machine Learning}

Before investigating the different algorithms that can be used to analyse data, a quick distinction should be drawn between different types of machine learning algorithms.

\begin{itemize}
 \item Supervised Learning
 \item Unsupervised Learning
 \item Semisupervised Learning
 \item Reinforcement Learning
 \item Deep Learning
\end{itemize}

Supervised learning happens when the model is trained on labelled data, that is, data that has been classified beforehand.
Conversely, in unsupervised learning all data is unlabelled and the model deduces the structure from it. In semisupervised learning, data can be labelled or unlabelled.
Reinforcement learning happens when the model is conditioned externally \parencite[11]{Ibrahim2021}.
Finally, deep learning involves a series of layers that process the data and feed into one another \parencite[13]{Ibrahim2021}.

\subsection{Predictive Algorithms}


\textcite{Jothi2015} outlined some of the classification algorithms commonly used in healthcare data analysis, briefly described next. All of them need exclusively labelled data and are thus considered supervised learning algorithms.

\begin{description}
    \item[Decision Tree] \textquote[{\cite[70]{Mueller2017}}]{They learn a hierarchy of if/else questions, leading to a decision}.
    \item[K-nearest Neighbour] Stores the training dataset, then to make a prediction it \textquote[{\cite[35]{Mueller2017}}]{finds the closest data points in the training dataset}.
    \item[Logistic Regression] Statistical model that \textquote{describes the relationship between a qualitative dependent variable and an independent variable}, making binary predictions \parencite{Nick2007}.
    \item[Bayesian Classifier] Each feature is analysed individually, then, per-class statistics are collected for each feature. 
    To make predictions, the \textquote[{\cite[69]{Mueller2017}}]{data point is compared to the statistics for each of the classes,
and the best matching class is predicted}.
    \item[Support Vector] It learns the importance of each training data point to \textquote[{\cite[98]{Mueller2017}}]{represent the decision boundary between two classes}.
    From those, only the ones at the border between classes are necessary to define the decision boundary, these are the support vectors.
    Classification is made based on the distances to the support vectors \parencite[98]{Mueller2017}.
\end{description}


Finally, another common approach in healthcare data analysis is Deep Learning, which encompasses several techniques that vary in complexity and design \parencite{Ibrahim2021}. Some deep learning architectures are:

\begin{itemize}
 \item Convolutional Neural Networks (CNN)
 \item Recurrent Neural Networks (RNN)
 \item Deep auto-encoders
\end{itemize}


\subsection{Training and Testing Approaches}

The training and testing approach chosen when designing the model is of great importance, since it can affect the accuracy of the model.
\textcite[39]{Consoli2019} suggests using the \(k\)-fold cross-validation approach, in which the dataset is split into \(k\) parts, of which \(k-1\) parts are used to train the model, and the last one is used to test it, rotating the data such that every part is used to test it once. \textcite{Wong2020} suggested 10-fold cross validation to be the best first approach, with 5-fold and 2-fold cross validation only being viable in circumstances where not enough elements exist in some fold (i.e. large-sample conditions are violated). It is worth mentioning \textit{stratified k-fold cross-validation}, in which the data is split such that there are proportional amounts of items of each class in each fold \parencite{Mueller2017}.

\subsection{Data Visualisation}

The way results are represented is important, since visualisations can make patterns apparent and provide insights that can alter the final decision \parencite{Hendriks2019}.
Transparency and lack of bias are desirable qualities in a visualisation technique \parencite{Hendriks2019}.

\section{Critical Evaluation of the case for or against uptake of such Technology}

% PROMPT
% You will evaluate the benefits or otherwise, including the challenges of applying machine learning algorithms, maintenance and ethical considerations of a data science model for business insight.
% ~400 words


\section{Conclusions and Recommendations}

Data Science has come a long way thanks to the advances in Machine Learning and Artificial Intelligence of the last few decades. The amount of literature that deals with analysis of healthcare data is vast, and covers technical areas such as sourcing, processing, cleaning, machine learning algorithms, deep learning, visualisation, and much more. These body of knowledge, along with current technology and tools make it possible to imagine a future where hospitals, researchers, and scientists harness their full potential. However, this should not cause privacy and consent to be undermined for the sake of research.

% ~150 words
\pagebreak
\printbibliography

\end{document}
